{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b237158-74cc-4371-9d58-5c98c093db48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "pdf_path = os.path.join('..', 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a93e65e-af31-4391-87a5-707bccc6cb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.pdf import PyPDFDirectoryLoader\n",
    "\n",
    "def load_documets():\n",
    "    document = PyPDFDirectoryLoader(pdf_path).load()\n",
    "    return document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25033708-9354-496c-9618-82a721463675",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.schema.document import Document\n",
    "\n",
    "def split_documents(documents: list[Document]):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "                    chunk_size=512,\n",
    "                    chunk_overlap=50,\n",
    "                    length_function=len,\n",
    "                    is_separator_regex=False\n",
    "                    )\n",
    "    return text_splitter.split_documents(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8975b69c-b523-411c-9330-b3ab94e586f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'pdfTeX-1.40.17',\n",
       " 'creator': 'LaTeX with acmart 2020/04/30 v1.71 Typesetting articles for the Association for Computing Machinery and hyperref 2016/06/24 v6.83q Hypertext links for LaTeX',\n",
       " 'creationdate': '2020-07-16T00:20:53+00:00',\n",
       " 'author': 'Yi Ren1*, Xu Tan2*, Tao Qin2, Jian Luan3, Zhou Zhao1, Tie-Yan Liu2',\n",
       " 'keywords': 'singing voice synthesis, singing data mining, web crawling, lyrics-to-singing alignment',\n",
       " 'moddate': '2020-07-16T00:20:53+00:00',\n",
       " 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2',\n",
       " 'subject': '-  Computing methodologies  ->  Natural language processing.-  Applied computing  ->  Sound and music computing.',\n",
       " 'title': 'DeepSinger: Singing Voice Synthesis with Data Mined From the Web',\n",
       " 'trapped': '/False',\n",
       " 'source': '../data/DeepSinger.pdf',\n",
       " 'total_pages': 12,\n",
       " 'page': 0,\n",
       " 'page_label': '1'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = load_documets()\n",
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e1d84d4-d45d-4a86-a806-11dd4e63c947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with acmart 2020/04/30 v1.71 Typesetting articles for the Association for Computing Machinery and hyperref 2016/06/24 v6.83q Hypertext links for LaTeX', 'creationdate': '2020-07-16T00:20:53+00:00', 'author': 'Yi Ren1*, Xu Tan2*, Tao Qin2, Jian Luan3, Zhou Zhao1, Tie-Yan Liu2', 'keywords': 'singing voice synthesis, singing data mining, web crawling, lyrics-to-singing alignment', 'moddate': '2020-07-16T00:20:53+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '-  Computing methodologies  ->  Natural language processing.-  Applied computing  ->  Sound and music computing.', 'title': 'DeepSinger: Singing Voice Synthesis with Data Mined From the Web', 'trapped': '/False', 'source': '../data/DeepSinger.pdf', 'total_pages': 12, 'page': 0, 'page_label': '1'}, page_content='DeepSinger: Singing Voice Synthesis with Data Mined\\nFrom the Web\\nYi Ren1âˆ—, Xu Tan2âˆ—, Tao Qin2, Jian Luan3, Zhou Zhao1â€ , Tie-Yan Liu2\\n1Zhejiang University, 2Microsoft Research Asia, 3Microsoft STC Asia\\nrayeren@zju.edu.cn,{xuta,taoqin,jianluan}@microsoft.com,zhaozhou@zju.edu.cn,tyliu@microsoft.com\\nABSTRACT\\nIn this paper1, we develop DeepSinger, a multi-lingual multi-singer\\nsinging voice synthesis (SVS) system, which is built from scratch us-\\ning singing training data mined from music websites. The pipeline')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = split_documents(docs)\n",
    "chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81d86100-9694-4b4c-b5ed-62f6d5bb51d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_chunk_ids(chunks):\n",
    "\n",
    "    # This will create IDs like \"data/monopoly.pdf:6:2\"\n",
    "    # Page Source : Page Number : Chunk Index\n",
    "\n",
    "    last_page_id = None\n",
    "    current_chunk_index = 0\n",
    "\n",
    "    for chunk in chunks:\n",
    "        source = chunk.metadata.get(\"source\")\n",
    "        page = chunk.metadata.get(\"page\")\n",
    "        current_page_id = f\"{source}:{page}\"\n",
    "\n",
    "        # If the page ID is the same as the last one, increment the index.\n",
    "        if current_page_id == last_page_id:\n",
    "            current_chunk_index += 1\n",
    "        else:\n",
    "            current_chunk_index = 0\n",
    "\n",
    "        # Calculate the chunk ID.\n",
    "        chunk_id = f\"{current_page_id}:{current_chunk_index}\"\n",
    "        last_page_id = current_page_id\n",
    "\n",
    "        # Add it to the page meta-data.\n",
    "        chunk.metadata[\"id\"] = chunk_id\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6848abe8-6d70-4498-b910-3d6fd1a3ef1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bb19862-7311-413a-9048-47b6752eab2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings.ollama import OllamaEmbeddings\n",
    "\n",
    "def get_embeddings_func():\n",
    "    embeddings = OllamaEmbeddings(model='nomic-embed-text')\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30ba34ff-c920-4364-aa81-9c0c5189b7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores.chroma import Chroma\n",
    "\n",
    "def add_to_chroma(chunks: list[Document]):\n",
    "    db = Chroma(\n",
    "\n",
    "        persist_directory= \"chroma\", embedding_function=get_embeddings_func()\n",
    "    )\n",
    "\n",
    "    chunks_with_ids = calculate_chunk_ids(chunks)\n",
    "\n",
    "    # Add or Update the documents.\n",
    "    existing_items = db.get(include=[])  # IDs are always included by default\n",
    "    existing_ids = set(existing_items[\"ids\"])\n",
    "    print(f\"Number of existing documents in DB: {len(existing_ids)}\")\n",
    "\n",
    "    # Only add documents that don't exist in the DB.\n",
    "    new_chunks = []\n",
    "    for chunk in chunks_with_ids:\n",
    "        if chunk.metadata[\"id\"] not in existing_ids:\n",
    "            new_chunks.append(chunk)\n",
    "\n",
    "    if len(new_chunks):\n",
    "        print(f\"ðŸ‘‰ Adding new documents: {len(new_chunks)}\")\n",
    "        new_chunk_ids = [chunk.metadata[\"id\"] for chunk in new_chunks]\n",
    "        db.add_documents(new_chunks, ids=new_chunk_ids)\n",
    "        db.persist()\n",
    "    else:\n",
    "        print(\"âœ… No new documents to add\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26e5f364-608a-44f5-a989-0945ebd9fd54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x0/_wkwvpks0kz17tm219vb7lvc0000gn/T/ipykernel_12025/3988799856.py:4: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embeddings = OllamaEmbeddings(model='nomic-embed-text')\n",
      "/var/folders/x0/_wkwvpks0kz17tm219vb7lvc0000gn/T/ipykernel_12025/2281887549.py:4: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  db = Chroma(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of existing documents in DB: 0\n",
      "ðŸ‘‰ Adding new documents: 203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x0/_wkwvpks0kz17tm219vb7lvc0000gn/T/ipykernel_12025/2281887549.py:26: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  db.persist()\n"
     ]
    }
   ],
   "source": [
    "add_to_chroma(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "023e2419-2724-45d1-b514-c5d82fe8cb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_community.llms.ollama import Ollama\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Answer the question based only on the following context:\n",
    "\n",
    "{context}\n",
    "\n",
    "---\n",
    "\n",
    "Answer the question based on the above context: {question}\n",
    "\"\"\"\n",
    "\n",
    "def query_rag(query_text: str):\n",
    "    # Prepare the DB.\n",
    "    embedding_function = get_embeddings_func()\n",
    "    db = Chroma(persist_directory='chroma', embedding_function=embedding_function)\n",
    "\n",
    "    # Search the DB.\n",
    "    results = db.similarity_search_with_score(query_text, k=5)\n",
    "\n",
    "    context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc, _score in results])\n",
    "    prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "    prompt = prompt_template.format(context=context_text, question=query_text)\n",
    "    # print(prompt)\n",
    "\n",
    "    model = Ollama(model=\"mistral\")\n",
    "    response_text = model.invoke(prompt)\n",
    "\n",
    "    sources = [doc.metadata.get(\"id\", None) for doc, _score in results]\n",
    "    formatted_response = f\"Response: {response_text}\\nSources: {sources}\"\n",
    "    # print(formatted_response)\n",
    "    return response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bb7cff1-c378-4d28-9135-426d8869fef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x0/_wkwvpks0kz17tm219vb7lvc0000gn/T/ipykernel_12025/609457665.py:27: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  model = Ollama(model=\"mistral\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The DeepSinger paper is about developing a system that can synthesize high-quality singing voices from data mined from music websites. It addresses the challenges of creating an SVS (Singling Voice Synthesis) system by designing a pipeline with several data mining and modeling steps, including data crawling, singing and accompaniment separation, lyrics-to-singing alignment, data filtration, and singing modeling. The contributions of this paper include the creation of the first SVS system mined from music websites and the ability to synthesize singing voices in multiple languages and for multiple singers.\n"
     ]
    }
   ],
   "source": [
    "response = query_rag(\"What the Deep singer paper about?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b35f05c-59d8-43fb-bdce-ff4daf666489",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
